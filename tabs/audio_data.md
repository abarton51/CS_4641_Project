---
layout: default
title: i. Audio Data Explained
---

# Audio Data

## Overview
Audio data comes in many different forms. MIDI, WAV, spectrograms, chroma vectors, etc. All of these data and file types are distinct from another in how they represent audio data. Generally, audio data comes in two forms: *audio signal* and *structured files* [[1.]](#references). Each type of data has its own benefits and downfalls regarding their capabilities in music information retrieval (MIR) as well as ease of processing them.

## What are MIDI Files?

MIDI stands for Musical Instrument Digital Interface. MIDI files are a type of digital file format used to represent music in a way that computers and electronic musical instruments can understand. Unlike audio files (e.g., MP3 or WAV), MIDI files do not contain actual audio recordings. Instead, they contain a set of instructions that describe how music should be played. These instructions include information about note pitch, duration, velocity (how forcefully a note is played), tempo, and other musical parameters.

MIDI files are versatile and lightweight, making them ideal for tasks like composer identification, as they focus on the musical structure and elements rather than the audio itself.

# References
[1.](https://dorienherremans.com/sites/default/files/Chapter_HerremansEtAl_preprint.pdf) Meredith, D., Herremans, D., Martens, D., &; Sorensen, K. (2016). 14. Composer Classification Models for Music-Theory Building. In Computational Music Analysis (pp. 369â€“392). Cham: Springer.