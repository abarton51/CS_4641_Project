<h1 align="center">Exploring Music Classification - Composers and Genres</h1>

![](https://github.com/abarton51/CS_4641_Project/blob/main/assets/images/robotmusic_icon1.png?raw=true)

<h3 align="center"><ins>Authors:</ins> Austin Barton, Karpagam Karthikeyan, Keyang Lu, Isabelle Murray, Aditya Radhakrishan</h3>


Check out our project website [**here**.](https://abarton51.github.io/CS_4641_Project/tabs/midterm.html).
***
## Abstract
&emsp; Classification as a machine learning task has been thoroughly studied and improved upon. However, audio data classification remains to be a particularly difficult simple task (by simple, we mean the task is straightforward and thoroughly understood). This is partly because audio data comes in a time series form that can be represented in a multitude of ways. For example, audio data can be converted to spectrogram PNG files and then treated as an image classification task, or audio data can be captured in MIDI files, which can then be parsed through and represented as a vector of feature values. Nevertheless, the amount of processing needed in order to thoroughly understand audio data and creating a model that can utilize this information to perform this task is a bit more nuanced than a simple image classification task, for example. Another reason audio data is so difficult is because of the extremely small sequential patterns that distinguish one set of audio samples from another. An experienced classical musician may be able to tell the difference between Bach and Beethoven, even on a song they've never heard before, simply because they understand the styles and intricacies of their compositions to make a distinction between the two. Or perhaps a metalhead that can listen to two songs from two sub-genres of metal and tell you one is black metal versus the other that is death metal. To an untrained ear, this task would be seemingly impossible, but through anecdotal evidence we see that it is not only possible but easy for many people. Therefore, we hope to be able to train machine learning models, provided they are designed well enough and the data it receives is good enough to make these distinctions, to be able to perform similarly. Lastly, music in particular can be subjective. Often times, a song will be labeled to a genre based on the feelings one may have when listening to it. We know that models exist that can label certain sentiments and emotions to sequential data, and we hope to be able to develop that can do the same for music data in addition to the other many features of audio data that can distinguish one genre from another, to make reliable genre classifications of songs.
***

***
## Directory
### folder1

### folder2

***
## References
